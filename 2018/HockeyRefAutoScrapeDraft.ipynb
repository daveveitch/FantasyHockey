{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to Download Hockey Reference Skater Stats into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping hockey-reference.com\n"
     ]
    }
   ],
   "source": [
    "print('Scraping hockey-reference.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Python Packages\n"
     ]
    }
   ],
   "source": [
    "print('Importing Python Packages')\n",
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current date\n",
    "current_date = datetime.datetime.now()\n",
    "current_date = current_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Site\n"
     ]
    }
   ],
   "source": [
    "print('Scraping Site')\n",
    "# Get HTML from HockeyReference and Parse w/BeautifulSoup\n",
    "page = requests.get('https://www.hockey-reference.com/leagues/NHL_2019_skaters.html')\n",
    "soup = BeautifulSoup(page.text,'lxml')\n",
    "table_body = soup.find('tbody')\n",
    "rows = table_body.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Data into Dataframe\n"
     ]
    }
   ],
   "source": [
    "print('Importing Data into Dataframe')\n",
    "# Scrape Player data into DF\n",
    "player_df = pd.DataFrame()\n",
    "\n",
    "for row in rows:\n",
    "    cols=row.find_all('td')\n",
    "    \n",
    "    if (len(cols) !=0):\n",
    "        # Player code derived from the hyperlink for each player, get this first\n",
    "        player_code = row.find_all('a',href=True)\n",
    "        player_code = re.search('/players/[a-z]/(.+?)\\.html',string=str(player_code[0])).group(1)\n",
    "        \n",
    "        # Other Infor in the column\n",
    "        cols=[x.get_text() for x in cols]\n",
    "        cols.append(player_code)\n",
    "        player_df = player_df.append([cols])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Player Code column consistent with previous player code in database\n",
    "player_df['player_code'] = player_df[0] + '\\\\' + player_df[27]\n",
    "\n",
    "# Rename columns\n",
    "player_df = player_df.rename(index=str, columns={'player_code':'player',1:'age',3:'pos',2:'team',4:'gp',5:'g',6:'a',7:'pts',8:'plusminus',9:'pim',\n",
    "                                                 10:'pointshares',11:'evg',12:'ppg',13:'shg',14:'gwg',15:'eva',16:'ppa',17:'sha',18:'sog',\n",
    "                                                 19:'sog_percent',20:'toi',21:'atoi',22:'blk',23:'hit',24:'fow',25:'fol',26:'fo_percent'})\n",
    "\n",
    "# force certain columns to numeric\n",
    "to_numeric_cols = ['age','gp','g','a','pts','plusminus','pim','pointshares','evg','ppg','shg','gwg','eva','ppa','sha','sog',\n",
    "                   'sog_percent','toi','atoi','blk','hit','fow','fol','fo_percent']\n",
    "player_df[to_numeric_cols] = player_df[to_numeric_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df = player_df.drop([0,27],axis=1)\n",
    "player_df = player_df.set_index('player')\n",
    "\n",
    "# create bogus rank column to align with database\n",
    "player_df['rk'] = 0\n",
    "\n",
    "# add ppp column\n",
    "player_df['ppp'] = player_df['ppg'] + player_df['ppa']\n",
    "\n",
    "# For players who played for multiple teams their team is set to TEAM1, TEAM2, TOT for total\n",
    "# this will only keep the TOT amount (better representation of how they did in a season)\n",
    "player_df = player_df[~player_df.index.duplicated(keep='first')]\n",
    "\n",
    "# adds season column to scraped data\n",
    "player_df['date'] = current_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to playerstats2019 table in Fantasy2018 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to SQL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SADeprecationWarning: reflect=True is deprecate; please use the reflect() method.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data previously written\n"
     ]
    }
   ],
   "source": [
    "print('Writing to SQL')\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import Table\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy import or_\n",
    "from sqlalchemy import and_\n",
    "\n",
    "# create connection to postgresql database\n",
    "engine = create_engine('postgresql+psycopg2://postgres:apple@localhost/Fantasy2018')\n",
    "\n",
    "# do a query to find out if there are any rows already in the table with the current_date\n",
    "# if there are then we will not write to the table (as this would duplicate entries)\n",
    "conn = engine.connect()\n",
    "meta = MetaData(engine,reflect=True)\n",
    "table = meta.tables['playerstats2019']\n",
    "\n",
    "select_st = select([table]).where(\n",
    "   table.c.date == current_date)\n",
    "res = conn.execute(select_st)\n",
    "res.rowcount\n",
    "\n",
    "# test to see if data for this date has already been written\n",
    "if res.rowcount>0:\n",
    "    print('data previously written')\n",
    "else:\n",
    "    player_df.to_sql('playerstats2019', engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrape Compelete\n"
     ]
    }
   ],
   "source": [
    "print('Scrape Compelete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
